{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will review and implement how to handle and prepare unlabeled data for injection attacks"
      ],
      "metadata": {
        "id": "mS6SE_LZMW_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Tools and dependencies"
      ],
      "metadata": {
        "id": "FSPAJG2UMqCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch sklearn pandas"
      ],
      "metadata": {
        "id": "JOfzHXbRLnN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the necessary libraries"
      ],
      "metadata": {
        "id": "lTtnYBmGMsTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MpKvv5RmLy6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Loading  "
      ],
      "metadata": {
        "id": "cb_-oX9jMx-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "labeled_data = pd.read_csv('/content/Complete_Label_train_Dataset - Copy of Train_Label_Dataset1 - Train_Label_Dataset.csv')\n",
        "non_labeled_data = pd.read_csv('/content/Non_Label_Dataset - Copy of Train_Label_Dataset1 - Train_Label_Dataset - Non_Label_Dataset - Copy of Train_Label_Dataset1 - Train_Label_Dataset.csv')\n",
        "\n",
        "# Use only partial labeled data for training\n",
        "partial_labeled_data = labeled_data.sample(n=150, random_state=42)\n"
      ],
      "metadata": {
        "id": "2kBdv-aiL9Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "iHFDChh-NFMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load XLM-RoBERTa tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# Function to generate embeddings\n",
        "def get_embeddings(texts):\n",
        "    tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.numpy()"
      ],
      "metadata": {
        "id": "kLnIlPAdNEwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ],
      "metadata": {
        "id": "2OQFN2muNJVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for labeled and non-labeled data\n",
        "print(\"Generating embeddings for partial labeled data...\")\n",
        "partial_labeled_data['embeddings'] = list(get_embeddings(partial_labeled_data['text'].tolist()))\n",
        "\n",
        "print(\"Generating embeddings for non-labeled data...\")\n",
        "non_labeled_data['embeddings'] = list(get_embeddings(non_labeled_data['text'].tolist()))\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "labeled_embeddings = normalize(np.vstack(partial_labeled_data['embeddings']))\n",
        "non_labeled_embeddings = normalize(np.vstack(non_labeled_data['embeddings']))"
      ],
      "metadata": {
        "id": "bUY8la7_NOTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cosine similarity and label assignment"
      ],
      "metadata": {
        "id": "-_Y1fSw0NSQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMDu_dquPJO",
        "outputId": "de67aefe-6f36-4bb0-f92d-04c855170fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for partial labeled data...\n",
            "Generating embeddings for non-labeled data...\n",
            "Assigning weak labels based on similarity...\n",
            "Weak labels assigned and saved!\n"
          ]
        }
      ],
      "source": [
        "# Calculate similarity and assign weak labels\n",
        "def assign_labels(non_labeled_embeddings, labeled_embeddings, labeled_labels):\n",
        "    weak_labels = []\n",
        "    for non_label_emb in non_labeled_embeddings:\n",
        "        # Compute similarity with all labeled samples\n",
        "        similarities = cosine_similarity([non_label_emb], labeled_embeddings)[0]\n",
        "        # Assign label of the most similar labeled sample\n",
        "        most_similar_idx = similarities.argmax()\n",
        "        weak_labels.append(labeled_labels[most_similar_idx])\n",
        "    return weak_labels\n",
        "\n",
        "print(\"Assigning weak labels based on similarity...\")\n",
        "non_labeled_data['weak_label'] = assign_labels(\n",
        "    non_labeled_embeddings,\n",
        "    labeled_embeddings,\n",
        "    partial_labeled_data['label'].tolist()\n",
        ")\n",
        "\n",
        "# Save the weakly labeled data\n",
        "non_labeled_data.to_csv('/content/Weakly_Labeled_Non_Label_Dataset.csv', index=False)\n",
        "print(\"Weak labels assigned and saved!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}